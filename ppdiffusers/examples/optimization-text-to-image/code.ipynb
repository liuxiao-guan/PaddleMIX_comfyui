{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2038bb57-a1c6-4a1c-9e54-fb0c4e709cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PaddleMIX'...\n",
      "remote: Enumerating objects: 16799, done.\u001b[K\n",
      "remote: Counting objects: 100% (367/367), done.\u001b[K\n",
      "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
      "remote: Total 16799 (delta 283), reused 235 (delta 235), pack-reused 16432 (from 2)\u001b[K\n",
      "Receiving objects: 100% (16799/16799), 167.12 MiB | 1.17 MiB/s, done.\n",
      "Resolving deltas: 100% (10449/10449), done.\n"
     ]
    }
   ],
   "source": [
    "# 克隆 PaddleMIX 仓库\n",
    "!git clone https://github.com/PaddlePaddle/PaddleMIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83de16e4-c9f2-4f9e-9d37-b1486576b789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX/ppdiffusers\n",
      "Obtaining file:///home/PaddleMIX/ppdiffusers\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting paddlenlp>=3.0.0b2 (from ppdiffusers==0.29.1)\n",
      "  Downloading paddlenlp-3.0.0b4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ppdiffusers==0.29.1) (0.4.4)\n",
      "Requirement already satisfied: ftfy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ppdiffusers==0.29.1) (6.2.3)\n",
      "Requirement already satisfied: regex in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ppdiffusers==0.29.1) (2024.7.24)\n",
      "Requirement already satisfied: Pillow in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ppdiffusers==0.29.1) (10.4.0)\n",
      "Collecting opencv-python (from ppdiffusers==0.29.1)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting av (from ppdiffusers==0.29.1)\n",
      "  Downloading av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting parameterized (from ppdiffusers==0.29.1)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting requests_mock (from ppdiffusers==0.29.1)\n",
      "  Downloading requests_mock-1.12.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting omegaconf (from ppdiffusers==0.29.1)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting note_seq (from ppdiffusers==0.29.1)\n",
      "  Downloading note_seq-0.0.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting urllib3<=2.0.0 (from ppdiffusers==0.29.1)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting einops>=0.6.1 (from ppdiffusers==0.29.1)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting paddlesde (from ppdiffusers==0.29.1)\n",
      "  Downloading paddlesde-0.2.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ligo-segments (from ppdiffusers==0.29.1)\n",
      "  Downloading ligo-segments-1.4.0.tar.gz (51 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface_hub in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ppdiffusers==0.29.1) (0.24.5)\n",
      "Collecting hf_transfer (from ppdiffusers==0.29.1)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting jieba (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting blobfile (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting colorlog (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting colorama (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting seqeval (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dill<0.3.5 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting multiprocess<=0.70.12.2 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading multiprocess-0.70.12.2-py39-none-any.whl.metadata (6.9 kB)\n",
      "Collecting datasets>=2.0.0 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (4.66.5)\n",
      "Collecting paddlefsl (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading paddlefsl-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting sentencepiece (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting onnx>=1.10.0 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting protobuf>=3.20.2 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting paddle2onnx (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading paddle2onnx-2.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting Flask-Babel (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading flask_babel-4.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting visualdl (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading visualdl-2.5.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting fastapi (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typer in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (0.12.3)\n",
      "Requirement already satisfied: rich in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (13.7.1)\n",
      "Collecting fast_dataindex>=0.1.1 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading fast_dataindex-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting aistudio-sdk>=0.1.3 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading aistudio_sdk-0.2.6-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (3.1.4)\n",
      "Requirement already satisfied: numpy<=1.26.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (1.26.4)\n",
      "Collecting tiktoken (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting ml_dtypes (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub->ppdiffusers==0.29.1) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub->ppdiffusers==0.29.1) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub->ppdiffusers==0.29.1) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub->ppdiffusers==0.29.1) (6.0.2)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub->ppdiffusers==0.29.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub->ppdiffusers==0.29.1) (4.12.2)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ftfy->ppdiffusers==0.29.1) (0.2.13)\n",
      "Requirement already satisfied: six in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from ligo-segments->ppdiffusers==0.29.1) (1.16.0)\n",
      "Collecting absl-py (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: attrs in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from note_seq->ppdiffusers==0.29.1) (24.2.0)\n",
      "Collecting bokeh>=0.12.0 (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading bokeh-3.7.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting intervaltree>=2.1.0 (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: IPython in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from note_seq->ppdiffusers==0.29.1) (8.26.0)\n",
      "Collecting librosa>=0.6.2 (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: pandas>=0.18.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from note_seq->ppdiffusers==0.29.1) (2.2.2)\n",
      "Collecting pretty-midi>=0.2.6 (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydub (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=0.18.1 (from note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->ppdiffusers==0.29.1)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boltons>=20.2.1 (from paddlesde->ppdiffusers==0.29.1)\n",
      "  Downloading boltons-25.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trampoline>=0.1.2 (from paddlesde->ppdiffusers==0.29.1)\n",
      "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting bce-python-sdk (from aistudio-sdk>=0.1.3->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading bce_python_sdk-0.9.29-py3-none-any.whl.metadata (416 bytes)\n",
      "Collecting prettytable (from aistudio-sdk>=0.1.3->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: click in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aistudio-sdk>=0.1.3->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (8.1.7)\n",
      "Collecting contourpy>=1.2 (from bokeh>=0.12.0->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting narwhals>=1.13 (from bokeh>=0.12.0->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading narwhals-1.35.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: tornado>=6.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from bokeh>=0.12.0->note_seq->ppdiffusers==0.29.1) (6.4.1)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh>=0.12.0->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading xyzservices-2025.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting xxhash (from datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting pybind11 (from fast_dataindex>=0.1.1->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree>=2.1.0->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (2.1.5)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting joblib>=1.0 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas>=0.18.1->note_seq->ppdiffusers==0.29.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas>=0.18.1->note_seq->ppdiffusers==0.29.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas>=0.18.1->note_seq->ppdiffusers==0.29.1) (2024.1)\n",
      "Collecting mido>=1.1.16 (from pretty-midi>=0.2.6->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub->ppdiffusers==0.29.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub->ppdiffusers==0.29.1) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub->ppdiffusers==0.29.1) (2024.7.4)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting lxml>=4.9 (from blobfile->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading lxml-5.3.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from fastapi->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (2.8.2)\n",
      "Requirement already satisfied: Babel>=2.12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from Flask-Babel->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (2.16.0)\n",
      "Collecting Flask>=2.0 (from Flask-Babel->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from IPython->note_seq->ppdiffusers==0.29.1) (4.9.0)\n",
      "Collecting onnxoptimizer==0.3.13 (from paddle2onnx->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading onnxoptimizer-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting polygraphy>=0.49.20 (from paddle2onnx->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading polygraphy-0.49.20-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from rich->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (3.0.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from typer->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from uvicorn->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (0.14.0)\n",
      "Collecting matplotlib (from visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting rarfile (from visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (6.0.0)\n",
      "Collecting Werkzeug>=3.1 (from Flask>=2.0->Flask-Babel->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.2 (from Flask>=2.0->Flask-Babel->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from Flask>=2.0->Flask-Babel->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jedi>=0.16->IPython->note_seq->ppdiffusers==0.29.1) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (0.1.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pexpect>4.3->IPython->note_seq->ppdiffusers==0.29.1) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pooch>=1.1->librosa>=0.6.2->note_seq->ppdiffusers==0.29.1) (4.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (2.20.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa>=0.6.2->note_seq->ppdiffusers==0.29.1)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa>=0.6.2->note_seq->ppdiffusers==0.29.1) (1.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (4.4.0)\n",
      "Collecting pycryptodome>=3.8.0 (from bce-python-sdk->aistudio-sdk>=0.1.3->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting future>=0.6.0 (from bce-python-sdk->aistudio-sdk>=0.1.3->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->visualdl->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from stack-data->IPython->note_seq->ppdiffusers==0.29.1) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from stack-data->IPython->note_seq->ppdiffusers==0.29.1) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from stack-data->IPython->note_seq->ppdiffusers==0.29.1) (0.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->paddlenlp>=3.0.0b2->ppdiffusers==0.29.1) (1.3.1)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.2->note_seq->ppdiffusers==0.29.1) (2.22)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading paddlenlp-3.0.0b4-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading note_seq-0.0.5-py3-none-any.whl (209 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading paddlesde-0.2.5-py3-none-any.whl (61 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading requests_mock-1.12.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading aistudio_sdk-0.2.6-py3-none-any.whl (34 kB)\n",
      "Downloading bokeh-3.7.2-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boltons-25.0.0-py3-none-any.whl (194 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Downloading fast_dataindex-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
      "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading flask_babel-4.0.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading paddle2onnx-2.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading onnxoptimizer-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (678 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading paddlefsl-1.1.0-py3-none-any.whl (101 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
      "Downloading visualdl-2.5.3-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lxml-5.3.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Downloading narwhals-1.35.0-py3-none-any.whl (325 kB)\n",
      "Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading polygraphy-0.49.20-py2.py3-none-any.whl (354 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading xyzservices-2025.1.0-py3-none-any.whl (88 kB)\n",
      "Downloading bce_python_sdk-0.9.29-py3-none-any.whl (343 kB)\n",
      "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Building wheels for collected packages: ligo-segments, antlr4-python3-runtime, intervaltree, pretty-midi, jieba, seqeval\n",
      "  Building wheel for ligo-segments (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ligo-segments: filename=ligo_segments-1.4.0-cp310-cp310-linux_x86_64.whl size=51599 sha256=419c5fd04de6d1af7777fbc9d7ed18181ade04fbef42e57f475dbd568f2717f6\n",
      "  Stored in directory: /home/.cache/pip/wheels/6d/48/d1/3466977be4e41ba57f92ad0d5619f083df43cf319a151c4e06\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144552 sha256=388147e549e6bb2a2deb32314386b3274b880755a40ca4bb46b21d4486e67edc\n",
      "  Stored in directory: /home/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26095 sha256=0099d265599d3b564f4bc5e73d3473cdfd994ad5939ba7e477912c1c9fe32f8b\n",
      "  Stored in directory: /home/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
      "  Building wheel for pretty-midi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretty-midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592288 sha256=3674311f7242b61d023b4bcc8cc3591e6873c8a1dea7d0bed7d5aaa9f7c5a3b3\n",
      "  Stored in directory: /home/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=8e4b5a84aca5ffa2ad4377ff19659604da4380ac7854af4065f02d77d3bca8c1\n",
      "  Stored in directory: /home/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a9390d365c0b5745ae6a7a8ec2ef774c2b13bb47168524ab1ad47afecebc5165\n",
      "  Stored in directory: /home/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built ligo-segments antlr4-python3-runtime intervaltree pretty-midi jieba seqeval\n",
      "Installing collected packages: trampoline, sortedcontainers, sentencepiece, pydub, jieba, antlr4-python3-runtime, xyzservices, xxhash, Werkzeug, uvicorn, urllib3, threadpoolctl, soxr, scipy, rarfile, pyparsing, pycryptodomex, pycryptodome, pybind11, pyarrow, protobuf, propcache, prettytable, polygraphy, parameterized, opencv-python, omegaconf, narwhals, multidict, msgpack, ml_dtypes, mido, lxml, llvmlite, ligo-segments, lazy_loader, kiwisolver, joblib, itsdangerous, intervaltree, hf_transfer, future, frozenlist, fonttools, einops, dill, cycler, contourpy, colorlog, colorama, boltons, blinker, av, audioread, async-timeout, aiohappyeyeballs, absl-py, yarl, starlette, soundfile, scikit-learn, pretty-midi, paddlesde, onnx, numba, multiprocess, matplotlib, Flask, fast_dataindex, blobfile, bce-python-sdk, aiosignal, tiktoken, seqeval, requests_mock, pooch, paddlefsl, onnxoptimizer, Flask-Babel, fastapi, bokeh, aistudio-sdk, aiohttp, visualdl, tokenizers, paddle2onnx, librosa, note_seq, datasets, paddlenlp, ppdiffusers\n",
      "\u001b[33m  WARNING: The script uvicorn is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pybind11-config is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script polygraphy is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts mido-connect, mido-play, mido-ports and mido-serve are installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyav is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts backend-test-tools, check-model and check-node are installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script flask is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script onnxoptimizer is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script fastapi is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script bokeh is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script aistudio is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script visualdl is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script paddle2onnx is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script paddlenlp is installed in '/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Legacy editable install of ppdiffusers==0.29.1 from file:///home/PaddleMIX/ppdiffusers (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for ppdiffusers\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.44.0 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.21.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-3.1.0 Flask-Babel-4.0.0 Werkzeug-3.1.3 absl-py-2.2.2 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 aistudio-sdk-0.2.6 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 audioread-3.0.1 av-14.3.0 bce-python-sdk-0.9.29 blinker-1.9.0 blobfile-3.0.0 bokeh-3.7.2 boltons-25.0.0 colorama-0.4.6 colorlog-6.9.0 contourpy-1.3.2 cycler-0.12.1 datasets-3.5.0 dill-0.3.4 einops-0.8.1 fast_dataindex-0.1.2 fastapi-0.115.12 fonttools-4.57.0 frozenlist-1.6.0 future-1.0.0 hf_transfer-0.1.9 intervaltree-3.1.0 itsdangerous-2.2.0 jieba-0.42.1 joblib-1.4.2 kiwisolver-1.4.8 lazy_loader-0.4 librosa-0.11.0 ligo-segments-1.4.0 llvmlite-0.44.0 lxml-5.3.2 matplotlib-3.10.1 mido-1.3.3 ml_dtypes-0.5.1 msgpack-1.1.0 multidict-6.4.3 multiprocess-0.70.12.2 narwhals-1.35.0 note_seq-0.0.5 numba-0.61.2 omegaconf-2.3.0 onnx-1.17.0 onnxoptimizer-0.3.13 opencv-python-4.11.0.86 paddle2onnx-2.0.1 paddlefsl-1.1.0 paddlenlp-3.0.0b4 paddlesde-0.2.5 parameterized-0.9.0 polygraphy-0.49.20 pooch-1.8.2 ppdiffusers pretty-midi-0.2.10 prettytable-3.16.0 propcache-0.3.1 protobuf-6.30.2 pyarrow-19.0.1 pybind11-2.13.6 pycryptodome-3.22.0 pycryptodomex-3.22.0 pydub-0.25.1 pyparsing-3.2.3 rarfile-4.2 requests_mock-1.12.1 scikit-learn-1.6.1 scipy-1.15.2 sentencepiece-0.2.0 seqeval-1.2.2 sortedcontainers-2.4.0 soundfile-0.13.1 soxr-0.5.0.post1 starlette-0.46.2 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.1 trampoline-0.1.2 urllib3-1.26.20 uvicorn-0.34.1 visualdl-2.5.3 xxhash-3.5.0 xyzservices-2025.1.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd PaddleMIX/ppdiffusers\n",
    "!pip install -e . --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab72fcf2-f5a6-48bd-93af-3ffbf6222ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX/ppdiffusers/examples/community/Hotshot-XL\n"
     ]
    }
   ],
   "source": [
    "%cd examples/community/Hotshot-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fb22eb-74cd-4397-8fd5-9bf1265e5895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /home/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.8.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9249744-1b4a-402e-a8ca-bd67c246c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                             convert_pre.sh  inference.py\n",
      "convert_controlnet.py                 fine_tune.py    requirements.txt\n",
      "convert_hotshot_xl_to_ppdiffusers.py  \u001b[0m\u001b[01;34mhotshot_xl\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908a0e69-8082-49d6-a143-8dcbcd96d3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'model/Hotshot-XL'...\n",
      "remote: Enumerating objects: 59, done.\u001b[K\n",
      "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
      "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
      "remote: Total 59 (delta 17), reused 59 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (59/59), 526.48 KiB | 814.00 KiB/s, done.\n",
      "Filtering content: 100% (6/6), 7.13 GiB | 31.40 MiB/s, done.\n",
      "Encountered 1 file(s) that may not have been copied correctly on Windows:\n",
      "\tunet/diffusion_pytorch_model.safetensors\n",
      "\n",
      "See: `git lfs help smudge` for more details.\n",
      "Cloning into 'code/Hotshot-XL'...\n",
      "remote: Enumerating objects: 125, done.\u001b[K\n",
      "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
      "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
      "remote: Total 125 (delta 47), reused 35 (delta 35), pack-reused 54 (from 1)\u001b[K\n",
      "Receiving objects: 100% (125/125), 85.95 KiB | 231.00 KiB/s, done.\n",
      "Resolving deltas: 100% (61/61), done.\n",
      "cp: -r not specified; omitting directory 'code/Hotshot-XL/hotshot_xl'\n"
     ]
    }
   ],
   "source": [
    "!sh convert_pre.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c1569a-ad75-406a-9267-52a9c729c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mPaddleMIX\u001b[0m/  Untitled-Copy1.ipynb  Untitled.ipynb  \u001b[01;34mwork\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c36bad-ca65-4935-989b-d013e5de5153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd PaddleMIX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa61049-11f7-40d0-83ea-fe22e76016af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CITATION.cff  \u001b[0m\u001b[01;34mapplications\u001b[0m/        \u001b[01;34mdocs\u001b[0m/                      \u001b[01;34mscripts\u001b[0m/\n",
      "LICENSE       build_env.sh         \u001b[01;34mpaddlemix\u001b[0m/                 setup.py\n",
      "\u001b[01;34mPaddleNLP\u001b[0m/    build_paddle_env.sh  paddlemix_applications.md  \u001b[01;34mtests\u001b[0m/\n",
      "README.md     check_env.sh         \u001b[01;34mppdiffusers\u001b[0m/\n",
      "README_EN.md  \u001b[01;34mcomfyui\u001b[0m/             pyproject.toml\n",
      "VERSION       \u001b[01;34mdeploy\u001b[0m/              requirements.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d1040b-0cc9-4a24-946f-157a1a38baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX/ppdiffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ppdiffusers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e336f87d-e892-405d-93cd-e7e3ac638dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE    VERSION             \u001b[0m\u001b[01;34mexamples\u001b[0m/              requirements.txt  \u001b[01;34mtests\u001b[0m/\n",
      "Makefile   \u001b[01;34mdeploy\u001b[0m/             \u001b[01;34mppdiffusers\u001b[0m/           \u001b[01;34mscripts\u001b[0m/\n",
      "README.md  \u001b[01;34mdeploy-deprecated\u001b[0m/  \u001b[01;34mppdiffusers.egg-info\u001b[0m/  setup.py\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521729be-f6df-4fe7-bf5d-72353b30a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX/ppdiffusers/examples/community/Hotshot-XL\n"
     ]
    }
   ],
   "source": [
    "cd examples/community/Hotshot-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00ce3dd-3f69-4860-847b-a652a59ff9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/inference.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"a smoking horse on the grassland, hd, high quality\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"horse.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d161aaf7-e1a9-498f-9565-d5d09ddb2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd PaddleMIX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95afd3e-f90e-47a9-931b-3a59016fbdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PaddleMIX/ppdiffusers/examples/community/Hotshot-XL\n"
     ]
    }
   ],
   "source": [
    "cd ppdiffusers/examples/community/Hotshot-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6d7f37-59b7-42c1-82f1-0ea728e0a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/PaddleMIX/ppdiffusers/examples/community/Hotshot-XL/inference.py\", line 20, in <module>\n",
      "    import paddle\n",
      "ModuleNotFoundError: No module named 'paddle'\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"a smoking horse on the grassland, hd, high quality\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"horse.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe62f9c-c646-4291-8b01-71f749343e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://www.paddlepaddle.org.cn/packages/stable/cu126/\n",
      "Collecting paddlepaddle-gpu==3.0.0\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/paddlepaddle-gpu/paddlepaddle_gpu-3.0.0-cp310-cp310-linux_x86_64.whl (1592.8 MB)\n",
      "Requirement already satisfied: httpx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/.local/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (6.30.2)\n",
      "Requirement already satisfied: Pillow in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (10.4.0)\n",
      "Requirement already satisfied: decorator in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (5.1.1)\n",
      "Collecting astor (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/astor/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting opt_einsum==3.3.0 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/opt-einsum/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (3.3)\n",
      "Requirement already satisfied: typing_extensions in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from paddlepaddle-gpu==3.0.0) (4.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cudnn-cu12/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cublas-cu12/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cufft-cu12/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-curand-cu12/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cusparselt-cu12/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Collecting nvidia-nccl-cu12==2.25.1 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-nccl-cu12/nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.4 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from paddlepaddle-gpu==3.0.0)\n",
      "  Using cached https://paddle-whl.bj.bcebos.com/stable/cu126/nvidia-cufile-cu12/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu==3.0.0) (4.4.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu==3.0.0) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: idna in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu==3.0.0) (3.7)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu==3.0.0) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx->paddlepaddle-gpu==3.0.0) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from anyio->httpx->paddlepaddle-gpu==3.0.0) (1.2.2)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, opt_einsum, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, astor, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, paddlepaddle-gpu\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.20\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.20:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.20\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.4.0 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.6.4.1 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.6.80 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.6.77 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.6.77 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.5.1.17 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.0.4 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.7.77 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.1.2 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.4.2 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.25.1 which is incompatible.\n",
      "torch 2.4.0 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvtx-cu12 12.6.77 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astor-0.8.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.25.1 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opt_einsum-3.3.0 paddlepaddle-gpu-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " !python -m pip install paddlepaddle-gpu==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681b04a5-6eaf-42a1-94fb-3a31835bd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 04:40:48.842974   747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 04:40:48.844012   747 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:  14%|█▊           | 1/7 [00:00<00:01,  3.42it/s]\u001b[32m[2025-04-19 04:40:49,270] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:40:49,273] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:40:54,223] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:40:54,826] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:40:54,826] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:05<00:16,  3.39s/it]\u001b[32m[2025-04-19 04:40:54,834] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:40:54,837] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:41:21,280] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:41:23,818] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:41:23,818] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:38<00:13,  6.76s/it]\n",
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   0%|  | 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   1%| | 10.5M/1.22G [00:18<35:28, 5\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   2%| | 21.0M/1.22G [00:20<16:25, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   3%| | 31.5M/1.22G [00:21<10:12, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   3%| | 41.9M/1.22G [00:23<07:11, 2\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   4%| | 52.4M/1.22G [00:24<05:26, 3\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   5%| | 62.9M/1.22G [00:25<04:18, 4\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   6%| | 73.4M/1.22G [00:26<03:32, 5\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   7%| | 83.9M/1.22G [00:27<02:59, 6\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   8%| | 94.4M/1.22G [00:28<02:34, 7\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   9%| | 105M/1.22G [00:29<02:16, 8.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:   9%| | 115M/1.22G [00:30<02:03, 8.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  10%| | 126M/1.22G [00:31<01:55, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  11%| | 136M/1.22G [00:32<01:48, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  12%| | 147M/1.22G [00:33<01:43, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  13%|▏| 157M/1.22G [00:34<01:40, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  14%|▏| 168M/1.22G [00:35<01:38, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  15%|▏| 178M/1.22G [00:36<01:35, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  15%|▏| 189M/1.22G [00:37<01:47, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  16%|▏| 199M/1.22G [00:39<02:04, 8.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  17%|▏| 210M/1.22G [00:41<02:15, 7.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  18%|▏| 220M/1.22G [00:42<02:14, 7.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  19%|▏| 231M/1.22G [00:43<02:11, 7.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  20%|▏| 241M/1.22G [00:45<02:05, 7.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  21%|▏| 252M/1.22G [00:46<02:00, 8.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  21%|▏| 262M/1.22G [00:47<01:54, 8.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  22%|▏| 273M/1.22G [00:48<01:46, 8.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  23%|▏| 283M/1.22G [00:49<01:41, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  24%|▏| 294M/1.22G [00:50<01:36, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  25%|▏| 304M/1.22G [00:51<01:30, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  26%|▎| 315M/1.22G [00:52<01:26, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  27%|▎| 325M/1.22G [00:53<01:24, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  27%|▎| 336M/1.22G [00:54<01:21, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  28%|▎| 346M/1.22G [00:55<01:33, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  29%|▎| 357M/1.22G [00:56<01:28, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  30%|▎| 367M/1.22G [00:57<01:23, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  31%|▎| 377M/1.22G [00:58<01:20, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  32%|▎| 388M/1.22G [00:59<01:17, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  33%|▎| 398M/1.22G [01:00<01:15, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  33%|▎| 409M/1.22G [01:01<01:14, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  34%|▎| 419M/1.22G [01:02<01:12, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  35%|▎| 430M/1.22G [01:03<01:11, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  36%|▎| 440M/1.22G [01:04<01:10, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  37%|▎| 451M/1.22G [01:04<01:09, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  38%|▍| 461M/1.22G [01:05<01:07, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  39%|▍| 472M/1.22G [01:06<01:06, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  39%|▍| 482M/1.22G [01:07<01:06, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  40%|▍| 493M/1.22G [01:08<01:04, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  41%|▍| 503M/1.22G [01:09<01:03, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  42%|▍| 514M/1.22G [01:11<01:14, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  43%|▍| 524M/1.22G [01:12<01:09, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  44%|▍| 535M/1.22G [01:12<01:06, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  45%|▍| 545M/1.22G [01:13<01:03, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  45%|▍| 556M/1.22G [01:14<01:01, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  46%|▍| 566M/1.22G [01:15<00:59, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  47%|▍| 577M/1.22G [01:16<00:58, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  48%|▍| 587M/1.22G [01:17<00:57, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  49%|▍| 598M/1.22G [01:18<00:56, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  50%|▍| 608M/1.22G [01:19<00:54, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  51%|▌| 619M/1.22G [01:20<00:54, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  51%|▌| 629M/1.22G [01:21<00:52, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  52%|▌| 640M/1.22G [01:22<00:52, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  53%|▌| 650M/1.22G [01:23<00:51, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  54%|▌| 661M/1.22G [01:24<00:49, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  55%|▌| 671M/1.22G [01:25<00:49, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  56%|▌| 682M/1.22G [01:26<00:56, 9.\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  57%|▌| 692M/1.22G [01:27<00:53, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  57%|▌| 703M/1.22G [01:28<00:50, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  58%|▌| 713M/1.22G [01:29<00:48, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  59%|▌| 724M/1.22G [01:30<00:46, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  60%|▌| 734M/1.22G [01:31<00:44, 10\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  61%|▌| 744M/1.22G [01:32<00:43, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  62%|▌| 755M/1.22G [01:33<00:42, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  63%|▋| 765M/1.22G [01:34<00:40, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  63%|▋| 776M/1.22G [01:34<00:39, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  64%|▋| 786M/1.22G [01:35<00:39, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  65%|▋| 797M/1.22G [01:36<00:37, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  66%|▋| 807M/1.22G [01:37<00:36, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  67%|▋| 818M/1.22G [01:38<00:36, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  68%|▋| 828M/1.22G [01:39<00:35, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  69%|▋| 839M/1.22G [01:40<00:34, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  69%|▋| 849M/1.22G [01:41<00:33, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  70%|▋| 860M/1.22G [01:42<00:32, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  71%|▋| 870M/1.22G [01:43<00:31, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  72%|▋| 881M/1.22G [01:44<00:30, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  73%|▋| 891M/1.22G [01:45<00:29, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  74%|▋| 902M/1.22G [01:46<00:28, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  75%|▋| 912M/1.22G [01:47<00:27, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  75%|▊| 923M/1.22G [01:48<00:26, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  76%|▊| 933M/1.22G [01:48<00:25, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  77%|▊| 944M/1.22G [01:49<00:24, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  78%|▊| 954M/1.22G [01:50<00:23, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  79%|▊| 965M/1.22G [01:51<00:22, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  80%|▊| 975M/1.22G [01:52<00:22, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  81%|▊| 986M/1.22G [01:53<00:21, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  81%|▊| 996M/1.22G [01:54<00:20, 11\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  82%|▊| 1.01G/1.22G [01:55<00:19, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  83%|▊| 1.02G/1.22G [01:56<00:18, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  84%|▊| 1.03G/1.22G [01:57<00:17, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  85%|▊| 1.04G/1.22G [01:58<00:16, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  86%|▊| 1.05G/1.22G [01:59<00:15, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  87%|▊| 1.06G/1.22G [02:00<00:14, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  88%|▉| 1.07G/1.22G [02:01<00:13, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  88%|▉| 1.08G/1.22G [02:02<00:12, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  89%|▉| 1.09G/1.22G [02:02<00:11, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  90%|▉| 1.10G/1.22G [02:03<00:10, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  91%|▉| 1.11G/1.22G [02:05<00:11, 9\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  92%|▉| 1.12G/1.22G [02:06<00:10, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  93%|▉| 1.13G/1.22G [02:07<00:08, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  94%|▉| 1.14G/1.22G [02:08<00:07, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  94%|▉| 1.15G/1.22G [02:09<00:06, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  95%|▉| 1.16G/1.22G [02:10<00:05, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  96%|▉| 1.17G/1.22G [02:10<00:04, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  97%|▉| 1.18G/1.22G [02:11<00:03, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  98%|▉| 1.20G/1.22G [02:12<00:02, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors:  99%|▉| 1.21G/1.22G [02:13<00:01, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors: 100%|▉| 1.22G/1.22G [02:14<00:00, 1\u001b[A\u001b[A\n",
      "\n",
      "(…)_paddle_model-00002-of-00002.safetensors: 100%|█| 1.22G/1.22G [02:15<00:00, 9\u001b[A\u001b[A\n",
      "\n",
      "Downloading shards: 100%|█████████████████████████| 2/2 [02:18<00:00, 69.46s/it]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|████████▌        | 1/2 [04:01<04:01, 242.00s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|█████████████████| 2/2 [04:03<00:00, 121.70s/it]\u001b[A\n",
      "Loading pipeline components...:  86%|██████████▎ | 6/7 [07:02<02:15, 135.13s/it]\n",
      "(…)hotshotxl/hotshot_output/vae/config.json: 100%|█| 720/720 [00:00<00:00, 2.14M\u001b[A\n",
      "\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:   0%|   | 0.00/335M [00:00<?, ?B/s]\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:   3%| | 10.5M/335M [00:14<07:24, 73\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:   6%| | 21.0M/335M [00:16<03:28, 1.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:   9%| | 31.5M/335M [00:17<02:11, 2.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  13%|▏| 41.9M/335M [00:19<01:33, 3.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  16%|▏| 52.4M/335M [00:20<01:11, 3.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  19%|▏| 62.9M/335M [00:21<00:56, 4.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  22%|▏| 73.4M/335M [00:23<00:46, 5.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  25%|▎| 83.9M/335M [00:24<00:39, 6.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  28%|▎| 94.4M/335M [00:25<00:34, 7.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  31%|▎| 105M/335M [00:26<00:29, 7.7\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  34%|▎| 115M/335M [00:27<00:26, 8.2\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  38%|▍| 126M/335M [00:28<00:23, 8.8\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  41%|▍| 136M/335M [00:29<00:21, 9.3\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  44%|▍| 147M/335M [00:30<00:19, 9.7\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  47%|▍| 157M/335M [00:31<00:17, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  50%|▌| 168M/335M [00:33<00:19, 8.7\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  53%|▌| 178M/335M [00:34<00:16, 9.2\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  56%|▌| 189M/335M [00:35<00:15, 9.6\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  60%|▌| 199M/335M [00:36<00:13, 9.9\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  63%|▋| 210M/335M [00:37<00:12, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  66%|▋| 220M/335M [00:38<00:11, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  69%|▋| 231M/335M [00:38<00:09, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  72%|▋| 241M/335M [00:39<00:08, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  75%|▊| 252M/335M [00:40<00:07, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  78%|▊| 262M/335M [00:41<00:06, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  81%|▊| 273M/335M [00:42<00:05, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  85%|▊| 283M/335M [00:44<00:05, 9.1\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  88%|▉| 294M/335M [00:45<00:04, 9.5\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  91%|▉| 304M/335M [00:46<00:03, 9.8\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  94%|▉| 315M/335M [00:47<00:01, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors:  97%|▉| 325M/335M [00:48<00:00, 10.\u001b[A\n",
      "(…)t/vae/diffusion_paddle_model.safetensors: 100%|█| 335M/335M [00:49<00:00, 6.7\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [08:00<00:00, 68.64s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.78it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"a smoking horse on the grassland, hd, high quality\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"horse.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57072754-deca-4c82-9db6-2951f2e4ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 04:57:45.298983  2370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 04:57:45.299899  2370 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[32m[2025-04-19 04:57:45,413] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:45,415] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:45,686] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:46,143] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:46,144] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:00<00:01,  2.55it/s]\u001b[32m[2025-04-19 04:57:46,149] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:46,150] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:47,487] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:49,669] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 04:57:49,670] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:11<00:05,  2.63s/it]\n",
      "Downloading shards: 100%|██████████████████████| 2/2 [00:00<00:00, 16163.02it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.13s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:07<00:00,  3.63s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:25<00:00,  3.58s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"a smoking horse on the grassland, hd, high quality\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"horse.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655ae01a-5613-4b91-b001-47d572eac638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 openai-1.75.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a8d61b-9bd7-483b-84b5-5416232a782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user wants to beautify the description of a picture for text-to-image generation. Let me start by understanding the original prompt: \"a smoking horse on the grassland, hd, high quality\". The main elements are a horse, smoking, grassland, HD, and high quality.\n",
      "\n",
      "First, I should expand on each element to make the description more vivid. For the horse, maybe specify the breed or color to add detail. \"Majestic stallion\" sounds better than just \"horse\". Then, \"smoking\" could be a cigarette or cigar, but since it's a horse, maybe a cigar would add a whimsical touch. Describing the smoke as \"wispy tendrils\" makes it more visual.\n",
      "\n",
      "The grassland can be enhanced by adding time of day, like \"golden hour\", which gives warm lighting. Mentioning the environment details like \"lush, sun-kissed meadow\" adds texture. Including elements like wildflowers and distant mountains can add depth to the background.\n",
      "\n",
      "HD and high quality are already covered, but using terms like \"ultra-detailed\" and \"4K resolution\" might be more specific for the model. Adding cinematic terms like \"dramatic lighting\" and \"hyper-realistic textures\" can improve the visual impact. Including \"vivid colors\" and \"dynamic composition\" ensures the image is lively and engaging.\n",
      "\n",
      "I should check if all elements from the original prompt are included and enhanced. Make sure there's a logical flow from the subject to the setting and then to the technical details. Avoid redundancy but ensure richness in description. Maybe mention the horse's posture, like \"head held high\" to convey confidence.\n",
      "\n",
      "Also, think about the overall atmosphere. Words like \"surreal\" and \"fantastical\" can give it a magical feel, which might make the image more striking. Combining all these aspects should create a detailed, appealing prompt for the text-to-image model.\n",
      "=================================================\n",
      "\"A majestic, muscular stallion with a sleek chestnut coat stands triumphantly on a vast, sun-drenched grassland, exhaling a swirl of silvery smoke from its nostrils that curls artistically into the golden-hour sky. The scene is bathed in warm, cinematic lighting with hyper-realistic textures—every strand of the horse's flowing mane, each blade of emerald-green grass, and the delicate wildflowers swaying in the breeze are rendered in stunning 4K detail. Dramatic volumetric clouds float above a distant mountain range, while the atmosphere glows with a subtle haze, blending surrealism and natural beauty. Ultra-high-definition, vivid colors, and dynamic composition evoke a sense of whimsical grandeur.\"\n"
     ]
    }
   ],
   "source": [
    "!python deepseek.py \"a smoking horse on the grassland, hd, high quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c328ee5a-19e8-46d8-bb85-41849b79cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 05:05:24.049686  3166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 05:05:24.050598  3166 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[32m[2025-04-19 05:05:24,163] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:24,166] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:24,409] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:24,861] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:24,861] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:00<00:01,  2.65it/s]\u001b[32m[2025-04-19 05:05:24,866] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:24,867] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:26,018] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:28,252] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:05:28,253] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:07<00:03,  1.57s/it]\n",
      "Downloading shards: 100%|██████████████████████| 2/2 [00:00<00:00, 15006.45it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.29s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.34s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:21<00:00,  3.05s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "\u001b[33m[2025-04-19 05:05:46,057] [ WARNING]\u001b[0m - Token indices sequence length is longer than the specified maximum sequence length for this model (147 > 77). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['of emerald - green grass, and the delicate wildflowers swaying in the breeze are rendered in stunning 4 k detail. dramatic volumetric clouds float above a distant mountain range, while the atmosphere glows with a subtle haze, blending surrealism and natural beauty. ultra - high - definition, vivid colors, and dynamic composition evoke a sense of whimsical grandeur.']\n",
      "\u001b[33m[2025-04-19 05:05:46,243] [ WARNING]\u001b[0m - Token indices sequence length is longer than the specified maximum sequence length for this model (147 > 77). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['of emerald - green grass, and the delicate wildflowers swaying in the breeze are rendered in stunning 4 k detail. dramatic volumetric clouds float above a distant mountain range, while the atmosphere glows with a subtle haze, blending surrealism and natural beauty. ultra - high - definition, vivid colors, and dynamic composition evoke a sense of whimsical grandeur.']\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"A majestic, muscular stallion with a sleek chestnut coat stands triumphantly on a vast, sun-drenched grassland, exhaling a swirl of silvery smoke from its nostrils that curls artistically into the golden-hour sky. The scene is bathed in warm, cinematic lighting with hyper-realistic textures—every strand of the horse's flowing mane, each blade of emerald-green grass, and the delicate wildflowers swaying in the breeze are rendered in stunning 4K detail. Dramatic volumetric clouds float above a distant mountain range, while the atmosphere glows with a subtle haze, blending surrealism and natural beauty. Ultra-high-definition, vivid colors, and dynamic composition evoke a sense of whimsical grandeur.\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"horse_new.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8429670d-893a-40a4-916c-a8cbd7655da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 05:19:36.808543  4643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 05:19:36.809484  4643 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[32m[2025-04-19 05:19:36,918] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:36,920] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:37,157] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:37,627] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:37,627] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:00<00:01,  2.62it/s]\u001b[32m[2025-04-19 05:19:37,632] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:37,634] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:38,755] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:40,978] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:19:40,979] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:06<00:02,  1.36s/it]\n",
      "Downloading shards: 100%|██████████████████████| 2/2 [00:00<00:00, 16131.94it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.03s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.19s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:19<00:00,  2.80s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.76it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"a shark swimming in the ocean, hd, high quality\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"shark.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0124f32-883c-49aa-8808-e0d520a80db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user wants me to beautify the description of a picture. The original prompt is \"a shark swimming in the ocean, hd, high quality\". They need this for text-to-image generation, so the refined prompt should be detailed and vivid to get the best results.\n",
      "\n",
      "First, I need to think about the elements that make a scene more visually appealing. Let's start with the shark. What kind of shark is it? Great white sharks are iconic and recognizable, so specifying that could help. Also, describing its movement: maybe \"majestically gliding\" instead of just swimming. Adding details about the shark's appearance, like \"pristine white underbelly contrasting with a sleek, slate-gray dorsal side\" would add depth.\n",
      "\n",
      "Next, the ocean environment. Clear, crystal-clear water is more vivid. Sunlight filtering through the water creates dynamic lighting. Maybe mention sunbeams creating shimmering rays as they penetrate the surface. This adds a sense of depth and atmosphere.\n",
      "\n",
      "The surroundings: coral reefs below with vibrant colors—electric blues, neon pinks, and golden yellows. Schools of tropical fish, like silver sardines and striped angelfish, darting around. This adds life and color to the scene. Including seaweed swaying gently in the current adds movement.\n",
      "\n",
      "Lighting effects: iridescent bubbles rising around the shark, catching the sunlight. This adds sparkle and detail. The ocean floor could have sun-dappled sand, which gives texture.\n",
      "\n",
      "Atmosphere terms like \"hyper-realistic\" and \"ultra-detailed\" might help the AI prioritize quality. Mentioning 8K resolution ensures sharpness. Cinematic lighting and dynamic composition could guide the style. Underwater perspective with a sense of motion and power in the shark's presence. Adding \"breathtaking aquatic scene\" wraps it up nicely.\n",
      "\n",
      "I need to structure all these elements into a coherent, flowing description without being too repetitive. Make sure each part adds to the visual without overcrowding. Check for adjectives and specifics that enhance each element. Alright, let's put it all together.\n",
      "=================================================\n",
      "A majestic great white shark glides effortlessly through the crystal-clear azure ocean, its powerful muscular body illuminated by golden sunbeams piercing the water's surface. The shark's pristine white underbelly contrasts starkly with its sleek slate-gray dorsal side, while faint scars along its flank hint at ancient oceanic battles. Sunlight fractures into shimmering prismatic rays that dance across vibrant coral reefs below, where schools of iridescent tropical fish dart between swaying kelp forests. Tiny air bubbles spiral upward like liquid mercury around the predator, catching fleeting rainbows in their curves. Hyper-realistic water textures reveal every undulating current and plankton particle in stunning 8K detail, with cinematic lighting emphasizing the shark's commanding presence in this dynamic underwater ecosystem. The composition balances raw predatory power with serene aquatic beauty, framed by deep cerulean voids fading into mysterious depths.\n"
     ]
    }
   ],
   "source": [
    "!python deepseek.py \"a shark swimming in the ocean, hd, high quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77264a3-adf2-4d52-88ba-dc245cd86f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 05:17:58.502494  4461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 05:17:58.503407  4461 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:  14%|█▊           | 1/7 [00:00<00:00,  9.19it/s]\u001b[32m[2025-04-19 05:17:58,671] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:17:58,674] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:17:58,907] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:17:59,365] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:17:59,365] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:00<00:02,  2.19it/s]\u001b[32m[2025-04-19 05:17:59,370] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:17:59,371] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:18:00,505] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:18:02,703] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:18:02,703] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:07<00:03,  1.54s/it]\n",
      "Downloading shards: 100%|██████████████████████| 2/2 [00:00<00:00, 16288.56it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.99s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.18s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:20<00:00,  2.95s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "\u001b[33m[2025-04-19 05:18:19,830] [ WARNING]\u001b[0m - Token indices sequence length is longer than the specified maximum sequence length for this model (179 > 77). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [\"across vibrant coral reefs below, where schools of iridescent tropical fish dart between swaying kelp forests. tiny air bubbles spiral upward like liquid mercury around the predator, catching fleeting rainbows in their curves. hyper - realistic water textures reveal every undulating current and plankton particle in stunning 8 k detail, with cinematic lighting emphasizing the shark's commanding presence in this dynamic underwater ecosystem. the composition balances raw predatory power with serene aquatic beauty, framed by deep cerulean voids fading into mysterious depths.\"]\n",
      "\u001b[33m[2025-04-19 05:18:20,007] [ WARNING]\u001b[0m - Token indices sequence length is longer than the specified maximum sequence length for this model (179 > 77). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [\"across vibrant coral reefs below, where schools of iridescent tropical fish dart between swaying kelp forests. tiny air bubbles spiral upward like liquid mercury around the predator, catching fleeting rainbows in their curves. hyper - realistic water textures reveal every undulating current and plankton particle in stunning 8 k detail, with cinematic lighting emphasizing the shark's commanding presence in this dynamic underwater ecosystem. the composition balances raw predatory power with serene aquatic beauty, framed by deep cerulean voids fading into mysterious depths.\"]\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.79it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"A majestic great white shark glides effortlessly through the crystal-clear azure ocean, its powerful muscular body illuminated by golden sunbeams piercing the water's surface. The shark's pristine white underbelly contrasts starkly with its sleek slate-gray dorsal side, while faint scars along its flank hint at ancient oceanic battles. Sunlight fractures into shimmering prismatic rays that dance across vibrant coral reefs below, where schools of iridescent tropical fish dart between swaying kelp forests. Tiny air bubbles spiral upward like liquid mercury around the predator, catching fleeting rainbows in their curves. Hyper-realistic water textures reveal every undulating current and plankton particle in stunning 8K detail, with cinematic lighting emphasizing the shark's commanding presence in this dynamic underwater ecosystem. The composition balances raw predatory power with serene aquatic beauty, framed by deep cerulean voids fading into mysterious depths.\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"shark_new.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51937efb-e512-4a8b-957d-d4bf43ddfc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 05:24:24.392943  5108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 05:24:24.393867  5108 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[32m[2025-04-19 05:24:24,505] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:24,508] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:24,742] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:25,207] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:25,207] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:00<00:01,  2.64it/s]\u001b[32m[2025-04-19 05:24:25,212] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:25,214] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:26,357] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:28,528] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:24:28,528] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:06<00:02,  1.38s/it]\n",
      "Downloading shards: 100%|██████████████████████| 2/2 [00:00<00:00, 15857.48it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:05<00:05,  5.31s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.20s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:18<00:00,  2.57s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.79it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"Fish are flying in the sky.\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"fish.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a794cd3-cf9f-4a4c-87ae-627b95b2084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user wants me to beautify the description \"Fish are flying in the sky.\" for a text-to-image prompt. Let me think about how to enhance this. First, I need to add more vivid details. Maybe specify the type of fish, like tropical or koi. Then, the sky – perhaps a clear azure sky with fluffy clouds. Lighting is important; maybe golden sunlight to make the colors pop. The fish could have iridescent scales shimmering in the light. Adding movement elements, like schools of fish gliding gracefully. The atmosphere should be surreal and magical. Maybe mention the environment below, like a serene meadow or mountains to contrast with the flying fish. Also, using words like \"ethereal\" and \"dreamlike\" to set the mood. Let me put it all together cohesively.\n",
      "=================================================\n",
      "A vibrant school of iridescent koi fish glide gracefully through a crystal-clear azure sky, their shimmering scales catching golden sunlight that filters through billowing cumulus clouds. Below, an emerald valley dotted with wildflowers gazes upward at this surreal spectacle, where turquoise fins ripple like silk ribbons in the warm breeze, creating a dreamlike fusion of ocean and atmosphere.\n"
     ]
    }
   ],
   "source": [
    "!python deepseek.py \"Fish are flying in the sky.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c204cad2-c0f6-4d1b-bc85-3dbc7094f37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0419 05:26:21.394830  5320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.8, Runtime API Version: 12.6\n",
      "W0419 05:26:21.395742  5320 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[32m[2025-04-19 05:26:21,513] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:21,515] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:21,755] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:22,242] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:22,243] [    INFO]\u001b[0m - All the weights of CLIPTextModel were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:00<00:01,  2.53it/s]\u001b[32m[2025-04-19 05:26:22,248] [    INFO]\u001b[0m - Loading configuration file /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/config.json\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:22,250] [    INFO]\u001b[0m - Loading weights file from cache at /home/.cache/paddlenlp/ppdiffusers/co63oc/hotshotxl/hotshot_output/text_encoder_2/model.safetensors\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:23,397] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:25,564] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing CLIPTextModelWithProjection.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-04-19 05:26:25,564] [    INFO]\u001b[0m - All the weights of CLIPTextModelWithProjection were initialized from the model checkpoint at co63oc/hotshotxl/hotshot_output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModelWithProjection for predictions without further training.\u001b[0m\n",
      "Loading pipeline components...:  71%|█████████▎   | 5/7 [00:07<00:02,  1.48s/it]\n",
      "Downloading shards: 100%|██████████████████████| 2/2 [00:00<00:00, 15827.56it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:07<00:07,  7.08s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.23s/it]\u001b[A\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:21<00:00,  3.10s/it]\n",
      "Warning - setting num_images_per_prompt = 1 because video_length = 8\n",
      "100%|███████████████████████████████████████████| 30/30 [00:31<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 10.79it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "  --prompt=\"A vibrant school of iridescent koi fish glide gracefully through a crystal-clear azure sky, their shimmering scales catching golden sunlight that filters through billowing cumulus clouds. Below, an emerald valley dotted with wildflowers gazes upward at this surreal spectacle, where turquoise fins ripple like silk ribbons in the warm breeze, creating a dreamlike fusion of ocean and atmosphere.\" \\\n",
    "  --seed 452 --precision f32 \\\n",
    "  --output=\"fish_new.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980186b-b37b-4e4b-8a96-002672ba395a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
